<!DOCTYPE html>
<html>
<head>
  <title>Clay Thomas</title>
  <link rel="stylesheet" href="style.css">
  <!-- https://stackoverflow.com/questions/27855154/website-elements-and-font-are-too-small-in-mobiles -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>
<div class="contents">

  <div class="header-image">
    <img src="TheNautalis.jpg" alt="The Nautalis in Vedauwoo, Wyoming"
      title="The Nautalis in Vedauwoo, Wyoming" />
  </div>

  <div class="profile-image">
    <img src="Profile.jpg" alt="Me, hanging around in Rocktown, GA" />
  </div>

  <div class="page-title">
    <h1>
      <span>
        Clay Thomas
      </span>
    </h1>
  </div>

  <div class="preface">
    <p>
      Hello! I'm a PhD student in the Computer Science Theory group at Princeton,
      where I'm very fortunate to be advised by Matt Weinberg.
      I study algorithmic game theory and mechanism design.
      I'm most inspired to study the true effect of strategic behavior on computational
      problems (possibly under different solution concepts or in average-case market behavior)
      and well-motivated combinatorics and discrete math questions that arise in
      algorithmic game theory or economics.
      Lately, I've been studying these themes in the topics of combinatorial auctions,
      matching markets, and social choice theory.
    </p>
    <!-- 
    <ul>
      <li>The true effect that strategic behavior has on computational problems,
        and the extent to which different solution concepts are really needed to
        encourage good outcomes
      </li>
      <li>The average-case behavior of markets and its effect on incentives,
        welfare, and fairness
      </li>
      <li>Well-motivated combinatorics and discrete math questions that arise in
        algorithmic game theory or economics
      </li>
    </ul>
    <p> In particular, I've been investigating the above themes in the settings of
    </p>
    <ul>
      <li> Combinatorial auctions, where I've been studying different query
        models and appropriate concepts of strategyproofness
      </li>
      <li> Matching markets, where I've been looking into worst-case upper bounds
        on the number of stable matches an instance can have, and various
        questions on average-case behavior and incentive properties
      </li>
      <li> Social choice theory, where I've been studying Condorcet domains
        (informally, sets of preferences which allow majority voting to work)
        and equitable social choice rules (which satisfy a good notion of
        "treating voters equally")
      </li>
    </ul>
    --> 
    <p>
      I completed my undergrad in Mathematics and Computer Science at
      Purdue University, where I was fortunate to work with
      Elena Grigorescu on error correcting codes.
      My other interests include functional programming, teaching, 
      rock climbing, and slacklining.
      Some fun links:
      <a href="./oeis/index.html">my OEIS
        contributions</a>,
      and <a href="climb/">my climbing homepage</a>.
    </p>
    <!-- <a href="cv.pdf">Here's my CV</a> -->
  </div>

  <!-- <h2>
    <span>
      News
    </span>
  </h2> -->
  <h2>
    <span>
      Drafts
    </span>
  </h2>

  <cite> 
    Linda Cai, Clayton Thomas, and S. Matthew Weinberg.
    <strong> Implementation in Advised Strategies:
    Welfare Guarantees from Posted-Price Mechanisms when Demand Queries are
    NP-hard.</strong>
    In submission. <a href="https://arxiv.org/abs/1910.04342">[arXiv]</a>
  </cite>
  <div class="abstract">
    <p>
    State-of-the-art posted-price mechanisms for submodular bidders with m items
    achieve approximation guarantees of \( O((\log\log m)^3)  \)
    [Assadi and Singla, 2019].
    Their truthfulness, however, requires bidders to compute an NP-hard
    demand-query. Some computational complexity of this form is unavoidable, as
    it is NP-hard for truthful mechanisms to guarantee even an
    \( m^{1/2−\epsilon} \)-approximation for any \( \epsilon>0 \) 
    [Dobzinski and Vondrák, 2016]. Together,
    these establish a stark distinction between computationally-efficient and
    communication-efficient truthful mechanisms.
    </p>
    <p>
    We show that this distinction disappears with a mild relaxation of
    truthfulness, which we term implementation in advised strategies.
    Specifically, advice maps a tentative strategy either to that same strategy
    itself, or one that dominates it. We say that a player follows advice as
    long as they never play actions which are dominated by advice. A poly-time
    mechanism guarantees an \(\alpha\)-approximation in implementation in advised
    strategies if there exists poly-time advice for each player such that an
    \(\alpha\)-approximation is achieved whenever all players follow advice. Using an
    appropriate bicriterion notion of approximate demand queries (which can be
    computed in poly-time), we establish that (a slight modification of) the
    [Assadi and Singla, 2019] mechanism achieves the same
    \(O((\log\log m)^3)\) approximation in implementation in advised strategies.
    </p>
  </div>

  <cite> 
    Linda Cai and Clayton Thomas.
    <strong> Representing All Stable Matchings by Walking a Maximal Chain. </strong>
    <a href="./papers/StableStructureMaxChain.pdf">[paper]</a>
  </cite>
  <div class="abstract">
    <p>
    The seminal book of Gusfield and Irving [GI89] provides a compact and algorithmically useful
    way to represent the collection of stable matches corresponding to a given set of preferences. In
    this paper, we reinterpret the main results of [GI89], giving a new proof of the characterization
    which is able to bypass a lot of the “theory building” of the original works. We also provide
    a streamlined and efficient way to compute this representation. Our proofs and algorithms
    emphasize the connection to well-known properties of the deferred acceptance algorithm.
    </p>
  </div>

  <cite> 
    Linda Cai and Clayton Thomas.
    <strong> The Short-Side Advantage in Random Matching Markets. </strong>
    <a href="./papers/ShortSideAdvantage.pdf">[paper]</a>
  </cite>
  <div class="abstract">
    <p>
    A recent breakthrough of Ashlagi, Kanoria, and Leshno [AKL17] found that imbalance in
    the number of agents on either side of a random matching market has a profound effect on
    the expected characteristics of the market. Specifically, across all stable matchings, the “long
    side” (i.e. the side with a greater number of agents) receives significantly worse matches in
    expectation than the short side. If matchings are found via the classic one-side proposing
    deferred acceptance algorithm, this indicates that the difference between the proposing and the
    receiving side is essentially unimportant compared to the difference between the long and the
    short side.
    </p>
    <p>
    We provide new intuition and a new proof for preliminary results in the direction of [AKL17],
    namely calculating the expected rank that an agent on the long side has for their optimal stable
    match.
    </p>
  </div>


  <h2>
    <span>
      Publications
    </span>
  </h2>

  <cite id="mrCodesBounded"> 
    V. Gandikota, E. Grigorescu, C. Thomas, and M. Zhu.
    <strong>Maximally recoverable codes: The bounded case.</strong>
    In <em>Allerton Conference on Communication, Control, and Computing</em>, 2017.
    <a href="./papers/boundedMRC.pdf">[paper]</a>
    <a href="./talks/boundedMRCSlides.pdf">[slides]</a>
  </cite>
  <div class="abstract">
    <p>
      Modern distributed storage systems employ Maximally Recoverable codes
      that aim to balance failure recovery capabilities with
      encoding/decoding efficiency tradeoffs. Recent works of Gopalan et al
      (SODA 2017) and Kane et al (FOCS 2017) show that the alphabet size of
      grid-like topologies of practical interest must be large, a feature that
      hampers decoding efficiency.
    </p>
    <p>
      To bypass such shortcomings, in this work we initiate the study of a
      weaker version of recoverability, where instead of being able to correct
      all correctable erasure patterns (as is the case for maximal
      recoverability), we only require to correct all  erasure patterns of
      <em>bounded</em> size. The study of this notion reduces to a variant of a
      combinatorial problem studied in the literature, which is  interesting
      in its own right.
    </p>
    <p>
      We study the alphabet size of  codes withstanding  all erasure patterns
      of small (constant) size. We believe the questions we propose are
      relevant  to both real storage systems and combinatorial analysis, and
      merit further study.
    </p>
  </div>

  <h2>
    <span>
      Course Projects
    </span>
  </h2>

  <cite id="johnsonExpansion">
    <strong> Paper Survey: Expansion in the Johnson Graph
     </strong>
    With Uma Girish.
    <a href="./papers/JohnsonExpansion.pdf">[report]</a>
  </cite>

  <div class="abstract">
    <p>
      The (generalized) Johnson graph is given by slices of the hypercube,
      and is important for under-standing probabilistically checkable proof
      systems and hardness of approximation. Characterizing the expansion of
      the Johnson Graph recently served as an important conceptual stepping
      stone to proving the 2-to-1 games conjecture. Here, we summarize the
      proof technique used, with a focus on simplicity and clarity of
      presentation.
    </p>
  </div>

  <cite id="taxactionComplexitySurvey">
    <strong> Paper Survey: New Lower Bound Techniques for the Query Complexity of
    Truthful Mechanisms. </strong>
    With Uma Girish.
    For Matt Weinberg's "Open Problems in AGT" course.
    <a href="./papers/EfficientQueryMechanisms.pdf">[report]</a>
  </cite>

  <div class="abstract">
    <p>
      A survey of "Computational Efficiency Requires Simple
      Taxation" by Shahar Dobzinski.
    </p>
  </div>

  <cite id="nextHopVerification">
    <strong> You Can't Handle the Lie: Next-Hop Verification in BGP.</strong>
    With Gavriel Hirsch.
    For Jennifer Rexford's "Advanced Networking" course.
    <a href="./papers/NextHopBGP.pdf">[report]</a>
  </cite>

  <div class="abstract">
    <p>
      BGP, the control-plane interdomain routing protocol used in today's
      internet, is notoriously difficult to secure and verify.
      This paper presents a new protocol called Next-Hop Verification,
      which reduces the set of contexts in which autonomous systems are 
      incentivized to lie while participating in BGP.
      The protocol works by sharing information
      about BGP path announcements between different ASs,
      using the existing structure of the network, and checking 
      those path announcements against the true flow of
      traffic in the data plane. We discuss the advantages and
      disadvantages of this new approach, and compare its effectiveness
      to that of previously considered verification
      techniques, focusing on cases where next-hop verification
      provably eliminates the incentives to lie in BGP.
      While our protocol is likely not practical, we believe it makes
      progress towards a more secure version of BGP in which ASs are able to
      "check each other" to enforce honesty.
    </p>
  </div>

  <cite id="structuralInvariants">
    <strong>Verifying Structural Invariants of Programs.</strong>
    With Jacob Bond.
    For Roopsha Samanta's "Reasoning about Programs" course at Purdue.
    <a href="./papers/structuralPerturbations.pdf">[report]</a>
    <a href="./talks/structuralPerturbationsSlides.pdf">[slides]</a>
  </cite>

  <div class="abstract">
    <p>
      A core problem in program verification is checking the invariance of
      programs under certain transformations. For example, a maximum
      function should be invariant under the order of a list,
      and a find function on binary search trees should return the same
      result for equivalent trees (i.e. those which represent the same
      ordered list).
      For both of these data types, we've found simple operations that
      "generate" all equivalent data types,
      in the sense that applying those permutations in some order to any data
      structure can result in all structures equivalent to the input.
      Thus, checking the invariance of programs for these data types can be
      reduced to checking their invariance under the more simple
      "generating" operations. This idea could potentially be useful for
      reasoning about algebraic data types with a notion of equivalence.
    </p>
    <p>
      We have a more general, sound procedure that can verify the
      invariance of an arbitrary data type under some underlying
      representation (for example, a function on binary search trees should be
      invariant under the function "list" that returns the ordered list
      corresponding to the tree).
      However, our procedure includes an inductive synthesizer and an
      equivalence-of-programs verifier in its inner loop,
      so it is not likely to be practical.
    </p>
  </div>

  <h2><span>Teaching</span></h2>

  <p>
    My teaching philosophy is best summed up by the following quote,
    from the first edition preface to Spivak's <em>Calculus</em>
    (some adjustments are my own).
  </p>

  <blockquote>
    Precision and rigor are neither deterrents to intuition,
    nor the ends in themselves,
    but the natural medium in which to formulate and think about
    <strike>mathematical</strike> <em>computer science</em> questions.
  </blockquote>

  <p>
    I am particularly interested in writing problem sets that both
    test and instruct students, and in crafting course policies and material 
    which is simultaneously accessible to all motivated learners and challenging for
    those looking for a deeper understanding of the material.
  </p>

  <p>
    Teaching experience:
  </p>

  <ul>
    <li> Fall 2019: Preceptor for 
      <a href="https://www.cs.princeton.edu/courses/archive/fall19/cos340/index.html">
        COS&nbsp;340 </a> (Reasoning about Computation) at Princeton.
    </li>
    <li> Spring and Fall 2015: Recitation Teaching Assistant for CS&nbsp;182
        (Foundations of Computer Science) at Purdue.
        I kept a small <a href="./teaching/cs182/index.html">homepage</a> with supplemental exercises I wrote.
    </li>
  </ul>

  <!--
  <p>
    Other educational resources:
    ((CURRENTLY IDEAS))
  </p>

  <ul>
    <li> TCS cheat sheets from those pages of note's I've been making
    </li>
  </ul>
  -->


  <!--
  <h2>
    <span>
      Small Projects
    </span>
  </h2>
  These are all smaller, simpler, code-based projects which I wrote
  independently. Some of them contain kernels of ideas which I would like to
  return to some day, so please contact me if these sound interesting and
  you would like to work on them!
  <h3> Fair Read-Write Locks </h3>
  <p>
    <span class="date">
      <a href="https://github.com/ClathomasPrime/FairReadWrite">
        March 2016.</a>
    </span>
    A kernel-level read-write lock implementation in the Xinu operating system,
    giving readers and writers access in exactly the order they request it.
  </p>
  <p>
    This small project inspired a question I really want to come
    back to one day:
    Are all synchronization protocols implementable with
    common sets of synchronization primitives?
    For example, is it possible to implement fair read-write locks
    using only semaphores?
    No implementation I have seen is actually fair in the
    sense discussed above.
    See the repo for more information.
  </p>
  <h3> Free Decision Trees &mdash; Library and Blog Post </h3>
  <p>
    <span class="date">
      <a href="hask/freeDecision.html">
        January 2016.</a>
    </span>
    A rudimentary library to train and apply decision trees
    represented in an elegant way.
    This project was inspired by the observation
    that the Haskell data type
    <code>Free ((->) r) Bool</code>
    could be used to represent decision trees.
    The result is a blog-post style explanation of the concept and implementation,
    which I think is a good way to understand free monads.
  </p>
  -->

  <!-- 
  <h2> <span> Other Things </span> </h2>
  <h3> Teaching </h3>
  <p>
    I enjoy lecturing and explaining foundational concepts.
    Furthermore, I like writing challenging and interesting practice
    questions for students (including thinking of exercises for myself!).
  </p>
  <p>
    When I TAed for Purdue's "Foundations of computer science" course,
    I wrote some lecture notes for a few of my "practice, study, observation"
    sessions and I wrote review materials for the midterm and final.
    You can find those materials
    <a href="cs182/index.html">here</a>.
  </p>
  <h3> Haskell </h3>
  <p>
    My manager at Facebook told me that there's an old saying among
    Haskellers: "The best way to learn monads is to write a monad tutorial,
    then throw it away" because nobody else will ever find it useful.
    Personally, I think monad tutorials are a myth.
    Writing a monad tutorial is like writing a "data structures" tutorial
    or a "programming patterns" tutorial: way too broad.
    Anyway, <a href="hask/listMonad.pdf">here's</a> my monad tutorial.
  </p>
  <p>
    I want make some simplified versions of Haskell libraries that are easier
    to understand so people can learn the concepts of the libraries.
    <a href="hask/lensExplanation.hs">Here's</a>
    the start of that project for the Lens library.
  </p>
  <h3> Stuff from the distant past </h3>
  <p>
    <a href="https://github.com/elliottwilliams/wheremeet">Here's</a>
    a hackathon project I worked on to help you meet your friends at
    different Purdue dining courts.
  </p>
  <p>
    <a href="misc/probs/fractionFunction.pdf">Here's</a>
    a Purdue problem of the week from back in the day.
    <a href="misc/probs/fractionFunctionPlot.pdf">Here</a>
    is a partial graph of the function constructed,
    where I enumerated rationals in some simple order
    and plotted the value of the function there.
    Seems like the graph is dense in the plane,
    but I don't think I even knew what "dense"
    meant at the time.
  </p>
  <p>
    <a href="misc/torusGraph.png">Here's</a>
    an image I made to explain how to
    derive an equation of the form <code>z = f(x,y)</code>
    for the graph of a Torus.
  </p>
  <p>
    <a href="misc/passwordProblem.pdf">Here's</a>
    a little writeup of a counting problem that
    I found tough and interesting at the time.
  </p>
  <p>
    <a href="misc/perfectRoll.pdf">Here's</a>
    a writeup I did when I took physics about the fact that objects always
    roll down slopes with less acceleration than if they were slipping
    down the slope without rolling.
    I also construct shapes with acceleration arbitrarily close to the
    "slipping acceleration".
  </p>
  -->


</div>
</body>
</html>
