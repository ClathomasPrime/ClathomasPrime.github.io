<!DOCTYPE html>
<html>
  <head>
    <title>Clay Thomas</title>
    <link rel="stylesheet" href="style.css">
  </head>
  <body>

    <div class="contents">
      <div class="header-image">
        <img src="TheNautalis.jpg" alt="The Nautalis in Vedauwoo, Wyoming"
          title="The Nautalis in Vedauwoo, Wyoming" />
      </div>

      <h1>
        Clay Thomas
      </h1>
      <div class="preface">
        <p>
          I'm a student finishing a double major in computer science and math at
          Purdue University.
        </p>
        <p>
          I'm interested in applying math to hard problems within computer science.
          In the future, I want to study either CS theory or programming languages.
          Within theoretical CS, I am interested in studying coding theory,
          complexity theory, sublinear algorithms, or communication theory.
          Within programming languages, I am most interested in studying type
          theory &mdash; possibly homotopy type theory.
        </p>
        <p>
          My other interests include rock climbing, gymnastics, and teaching.
        </p>
        <a href="cv.pdf">Here's my CV</a>
      </div>

      <h2>
        Publications
      </h2>

      <cite id="mrCodesBounded"> 
        V. Gandikota, E. Grigorescu, C. Thomas, and M. Zhu.
        Maximally recoverable codes: The bounded case.
        In <em>Allerton Conference on Communication, Control, and Computing</em>, 2017.
      </cite>
      <div class="abstract">
        <p>
          Modern distributed storage systems employ Maximally Recoverable codes
          that aim to balance failure recovery capabilities with
          encoding/decoding efficiency tradeoffs. Recent works of Gopalan et al
          (SODA 2017) and Kane et al (FOCS 2017) show that the alphabet size of
          grid-like topologies of practical interest must be large, a feature that
          hampers decoding efficiency.
        </p>
        <p>
          To bypass such shortcomings, in this work we initiate the study of a
          weaker version of recoverability, where instead of being able to correct
          all correctable erasure patterns (as is the case for maximal
          recoverability), we only require to correct all  erasure patterns of
          <em>bounded</em> size. The study of this notion reduces to a variant of a
          combinatorial problem studied in the literature, which is  interesting
          in its own right.
        </p>
        <p>
          We study the alphabet size of  codes withstanding  all erasure patterns
          of small (constant) size. We believe the questions we propose are
          relevant  to both real storage systems and combinatorial analysis, and
          merit further study.
        </p>
      </div>

      <h2>
        Projects
      </h2>

      <h2>
        Teaching
      </h2>
      <p>
        I enjoy lecturing and explaining foundational concepts.
        Furthermore, I like writing challenging and interesting practice
        questions for students (including thinking of exercises for myself!).
      </p>
      <p>
        When I TAed for Purdue's "Foundations of computer science" course,
        I wrote some lecture notes for a few of my "practice, study, observation"
        sessions and I wrote review materials for the midterm and final.
        You can find those materials
        <a href="cs182/index.html">here</a>.
      </p>

      <h2>
        Smaller Projects
      </h2>

    </div>
  </body>
</html>
